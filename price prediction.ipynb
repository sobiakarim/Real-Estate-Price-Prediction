{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0e2a31f9",
      "metadata": {
        "id": "0e2a31f9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer, PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, silhouette_score, davies_bouldin_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('portugal_listinigs2.csv', low_memory=False)\n",
        "\n",
        "# Target and Features\n",
        "y = df['Price']\n",
        "X = df.drop(columns=['Price'])\n",
        "\n",
        "X = X[~y.isna()]\n",
        "y = y[~y.isna()]\n",
        "\n",
        "# Cap outliers in target\n",
        "y = y.clip(lower=y.quantile(0.01), upper=y.quantile(0.99))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Column types\n",
        "numeric_columns = ['Parking', 'TotalArea', 'LivingArea', 'TotalRooms', 'NumberOfBathrooms']\n",
        "categorical_columns = ['District', 'City', 'Type', 'EnergyCertificate', 'Elevator', 'ConstructionYear']\n",
        "\n",
        "# Fix dtype\n",
        "for col in categorical_columns:\n",
        "    X_train[col] = X_train[col].astype(str)\n",
        "    X_test[col] = X_test[col].astype(str)\n",
        "\n",
        "# Custom functions for preprocessing\n",
        "def random_impute(X, columns=['ConstructionYear']):\n",
        "    X = pd.DataFrame(X, columns=columns) if isinstance(X, np.ndarray) else X\n",
        "    for col in columns:\n",
        "        missing = X[col].isna()\n",
        "        X.loc[missing, col] = np.random.randint(1960, 2020, size=missing.sum())\n",
        "    return X\n",
        "\n",
        "def cap_outliers_iqr(X, columns):\n",
        "    X = pd.DataFrame(X, columns=columns) if isinstance(X, np.ndarray) else X\n",
        "    for col in columns:\n",
        "        Q1, Q3 = X[col].quantile([0.25, 0.75])\n",
        "        IQR = Q3 - Q1\n",
        "        X[col] = X[col].clip(Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
        "    return X\n",
        "\n",
        "class TopCategoriesEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, top_n=4):\n",
        "        self.top_n = top_n\n",
        "        self.top_categories_ = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = pd.DataFrame(X)\n",
        "        for col in X.columns:\n",
        "            self.top_categories_[col] = list(X[col].value_counts().nlargest(self.top_n).index)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.DataFrame(X)\n",
        "        X_new = pd.DataFrame()\n",
        "        for col in X.columns:\n",
        "            top = self.top_categories_[col]\n",
        "            X_temp = X[col].apply(lambda x: x if x in top else 'Other')\n",
        "            dummies = pd.get_dummies(X_temp, prefix=col, drop_first=False)\n",
        "            X_new = pd.concat([X_new, dummies], axis=1)\n",
        "        return X_new\n",
        "\n",
        "# Preprocessing pipelines\n",
        "numeric_preprocessor = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('outlier_cap', FunctionTransformer(cap_outliers_iqr, validate=False, kw_args={'columns': numeric_columns})),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_preprocessor = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('top_encoder', TopCategoriesEncoder(top_n=4))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_preprocessor, numeric_columns),\n",
        "    ('cat', categorical_preprocessor, categorical_columns)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('random_impute', FunctionTransformer(random_impute, validate=False, kw_args={'columns': ['ConstructionYear']})),\n",
        "    ('preprocessor', preprocessor)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "C8g2BqAe5898",
      "metadata": {
        "id": "C8g2BqAe5898"
      },
      "outputs": [],
      "source": [
        "# Transform the data\n",
        "X_train_transformed = pipeline.fit_transform(X_train)\n",
        "X_test_transformed = pipeline.transform(X_test)\n",
        "y_train = y_train.values.reshape(-1, 1)\n",
        "y_test = y_test.values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2Kc-2y0m6CH3",
      "metadata": {
        "id": "2Kc-2y0m6CH3"
      },
      "outputs": [],
      "source": [
        "# Add bias term\n",
        "X_train = np.hstack([np.ones((X_train_transformed.shape[0], 1)), X_train_transformed])\n",
        "X_test = np.hstack([np.ones((X_test_transformed.shape[0], 1)), X_test_transformed])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0lOSVWri6GA4",
      "metadata": {
        "id": "0lOSVWri6GA4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred, X_test, model_name):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    n, k = len(y_true), X_test.shape[1] - 1\n",
        "    adj_r2 = 1 - ((1 - r2) * (n - 1)) / (n - k - 1)\n",
        "    print(f\"\\n{model_name}\")\n",
        "    print(f\"MAE: {mae:.2f} | MSE: {mse:.2f} | RMSE: {rmse:.2f} | R2: {r2:.4f} | Adj R2: {adj_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Pzbi9hzD6rwf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzbi9hzD6rwf",
        "outputId": "8508a1d8-1c66-4a0a-b1c2-5ca0c4fe55a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (103632, 34)\n",
            "Shape of y_train: (103632, 1)\n",
            "Shape of X_test: (25909, 34)\n",
            "Shape of y_test: (25909, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "tG-f94AB6G52",
      "metadata": {
        "id": "tG-f94AB6G52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mini-Batch GD\n",
            "MAE: 205050.49 | MSE: 129848940864.51 | RMSE: 360345.59 | R2: 0.3299 | Adj R2: 0.3291\n"
          ]
        }
      ],
      "source": [
        "# Gradient Descent Methods\n",
        "\n",
        "def mini_batch_gradient_descent(X, y, lr=0.1, n_iters=1000, batch_size=32):\n",
        "    theta = np.zeros((X.shape[1], 1))\n",
        "    for _ in range(n_iters):\n",
        "        indices = np.random.permutation(X.shape[0])\n",
        "        X_shuf, y_shuf = X[indices], y[indices]\n",
        "        for start in range(0, X.shape[0], batch_size):\n",
        "            end = start + batch_size\n",
        "            xi, yi = X_shuf[start:end], y_shuf[start:end]\n",
        "            theta -= lr * (xi.T @ (xi @ theta - yi)) / batch_size\n",
        "    return theta\n",
        "\n",
        "# Train all models\n",
        "models = {\n",
        "    \"Mini-Batch GD\": mini_batch_gradient_descent(X_train, y_train)\n",
        "}\n",
        "\n",
        "for name, theta in models.items():\n",
        "    y_pred = X_test @ theta\n",
        "    evaluate_model(y_test, y_pred, X_test, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "wV0kd4Oa718R",
      "metadata": {
        "id": "wV0kd4Oa718R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Linear Regression\n",
            "MAE: 207324.97 | MSE: 128369980599.29 | RMSE: 358287.57 | R2: 0.3375 | Adj R2: 0.3367\n",
            "\n",
            "Ridge Regression\n",
            "MAE: 207354.78 | MSE: 128372237851.68 | RMSE: 358290.72 | R2: 0.3375 | Adj R2: 0.3367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PMYLS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.193e+14, tolerance: 3.189e+12\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Lasso Regression\n",
            "MAE: 207360.05 | MSE: 128373442511.89 | RMSE: 358292.40 | R2: 0.3375 | Adj R2: 0.3367\n",
            "\n",
            "ElasticNet Regression\n",
            "MAE: 201494.09 | MSE: 130559300275.73 | RMSE: 361329.91 | R2: 0.3262 | Adj R2: 0.3254\n"
          ]
        }
      ],
      "source": [
        "# Sklearn Regressors\n",
        "reg_models = {\n",
        "    \"Linear Regression\": LinearRegression(fit_intercept=False),\n",
        "    \"Ridge Regression\": Ridge(alpha=1.0, fit_intercept=False),\n",
        "    \"Lasso Regression\": Lasso(alpha=0.1, fit_intercept=False),\n",
        "    \"ElasticNet Regression\": ElasticNet(alpha=0.1, l1_ratio=0.5, fit_intercept=False)\n",
        "}\n",
        "\n",
        "for name, model in reg_models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    evaluate_model(y_test, y_pred, X_test, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "u3ObPpeZh4Oe",
      "metadata": {
        "id": "u3ObPpeZh4Oe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PMYLS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RandomForest (Train)\n",
            "MAE: 153123.99 | MSE: 83774848103.48 | RMSE: 289438.85 | R2: 0.5659 | Adj R2: 0.5658\n",
            "\n",
            "RandomForest (Test)\n",
            "MAE: 160640.42 | MSE: 96021744397.80 | RMSE: 309873.76 | R2: 0.5045 | Adj R2: 0.5038\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=20,   \n",
        "    max_depth=10,        \n",
        "    min_samples_leaf=3,   \n",
        "    random_state=42,\n",
        "    n_jobs=-1             \n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on Training Set\n",
        "y_train_pred = rf.predict(X_train)\n",
        "evaluate_model(y_train, y_train_pred, X_train, \"RandomForest (Train)\")\n",
        "\n",
        "# Evaluate on Testing Set\n",
        "y_test_pred = rf.predict(X_test)\n",
        "evaluate_model(y_test, y_test_pred, X_test, \"RandomForest (Test)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "38bcdd74",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DecisionTree (Train)\n",
            "MAE: 156959.76 | MSE: 88607975464.78 | RMSE: 297670.92 | R2: 0.5409 | Adj R2: 0.5407\n",
            "\n",
            "DecisionTree (Test)\n",
            "MAE: 164625.64 | MSE: 101642359330.55 | RMSE: 318813.99 | R2: 0.4755 | Adj R2: 0.4748\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor(\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on Training Set\n",
        "y_train_pred = dt.predict(X_train)\n",
        "evaluate_model(y_train, y_train_pred, X_train, \"DecisionTree (Train)\")\n",
        "\n",
        "# Evaluate on Testing Set\n",
        "y_test_pred = dt.predict(X_test)\n",
        "evaluate_model(y_test, y_test_pred, X_test, \"DecisionTree (Test)\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
